name: Deploy ML Model to AWS

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

# Add permissions for security scanning
permissions:
  contents: read
  security-events: write
  actions: read

env:
  AWS_REGION: us-east-2
  ECR_REPOSITORY: ml-devops-dev-ml-model
  ECS_SERVICE: ml-devops-dev-service
  ECS_CLUSTER: ml-devops-dev-cluster
  ECS_TASK_DEFINITION: ml-devops-dev-task

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        cd ml-model
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run tests
      run: |
        cd ml-model
        python -m pytest tests/ -v

    - name: Run linting
      run: |
        cd ml-model
        flake8 app.py
        black --check app.py

  infrastructure:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0

    - name: Terraform Format Check
      run: terraform fmt -check
      working-directory: infrastructure

    - name: Terraform Init
      run: terraform init
      working-directory: infrastructure

    - name: Terraform Validate
      run: terraform validate
      working-directory: infrastructure

    - name: Import Existing Resources
      run: |
        echo "Checking for existing resources and importing them..."
        
        # Function to safely import resource
        import_resource() {
          local resource_name=$1
          local aws_resource_id=$2
          local check_command=$3
          
          echo "Checking if $resource_name exists in state..."
          if ! terraform state show "$resource_name" >/dev/null 2>&1; then
            echo "Resource $resource_name not in state, checking if it exists in AWS..."
            if eval "$check_command" >/dev/null 2>&1; then
              echo "Importing existing resource: $resource_name ($aws_resource_id)"
              terraform import "$resource_name" "$aws_resource_id" || echo "Import failed for $resource_name, will be handled during apply"
            else
              echo "Resource $aws_resource_id does not exist in AWS, will be created"
            fi
          else
            echo "Resource $resource_name already in state"
          fi
        }
        
        # Get VPC ID first (needed for many resources)
        VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ml-devops-dev-vpc" --query 'Vpcs[0].VpcId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        echo "Found VPC ID: $VPC_ID"
        
        # ===== VPC MODULE RESOURCES =====
        echo "=== Importing VPC Module Resources ==="
        
        # Import VPC
        if [ ! -z "$VPC_ID" ] && [ "$VPC_ID" != "None" ]; then
          import_resource "module.vpc.aws_vpc.main" "$VPC_ID" "aws ec2 describe-vpcs --vpc-ids $VPC_ID --region ${{ env.AWS_REGION }}"
          
          # Import Internet Gateway
          IGW_ID=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          if [ ! -z "$IGW_ID" ] && [ "$IGW_ID" != "None" ]; then
            import_resource "module.vpc.aws_internet_gateway.main" "$IGW_ID" "aws ec2 describe-internet-gateways --internet-gateway-ids $IGW_ID --region ${{ env.AWS_REGION }}"
          fi
          
          # Import Public Subnets
          for i in 0 1 2; do
            SUBNET_ID=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-public-subnet-$((i+1))" --query 'Subnets[0].SubnetId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_ID" ] && [ "$SUBNET_ID" != "None" ]; then
              import_resource "module.vpc.aws_subnet.public[$i]" "$SUBNET_ID" "aws ec2 describe-subnets --subnet-ids $SUBNET_ID --region ${{ env.AWS_REGION }}"
            fi
          done
          
          # Import Private Subnets
          for i in 0 1 2; do
            SUBNET_ID=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-private-subnet-$((i+1))" --query 'Subnets[0].SubnetId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_ID" ] && [ "$SUBNET_ID" != "None" ]; then
              import_resource "module.vpc.aws_subnet.private[$i]" "$SUBNET_ID" "aws ec2 describe-subnets --subnet-ids $SUBNET_ID --region ${{ env.AWS_REGION }}"
            fi
          done
          
          # Import Elastic IPs for NAT Gateways
          for i in 0 1 2; do
            EIP_ID=$(aws ec2 describe-addresses --filters "Name=tag:Name,Values=ml-devops-dev-nat-eip-$((i+1))" --query 'Addresses[0].AllocationId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$EIP_ID" ] && [ "$EIP_ID" != "None" ]; then
              import_resource "module.vpc.aws_eip.nat[$i]" "$EIP_ID" "aws ec2 describe-addresses --allocation-ids $EIP_ID --region ${{ env.AWS_REGION }}"
            fi
          done
          
          # Import NAT Gateways
          for i in 0 1 2; do
            NAT_GW_ID=$(aws ec2 describe-nat-gateways --filter "Name=tag:Name,Values=ml-devops-dev-nat-gateway-$((i+1))" --query 'NatGateways[0].NatGatewayId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$NAT_GW_ID" ] && [ "$NAT_GW_ID" != "None" ]; then
              import_resource "module.vpc.aws_nat_gateway.main[$i]" "$NAT_GW_ID" "aws ec2 describe-nat-gateways --nat-gateway-ids $NAT_GW_ID --region ${{ env.AWS_REGION }}"
            fi
          done
          
          # Import Public Route Table
          PUBLIC_RT_ID=$(aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-public-rt" --query 'RouteTables[0].RouteTableId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          if [ ! -z "$PUBLIC_RT_ID" ] && [ "$PUBLIC_RT_ID" != "None" ]; then
            import_resource "module.vpc.aws_route_table.public" "$PUBLIC_RT_ID" "aws ec2 describe-route-tables --route-table-ids $PUBLIC_RT_ID --region ${{ env.AWS_REGION }}"
          fi
          
          # Import Private Route Tables
          for i in 0 1 2; do
            PRIVATE_RT_ID=$(aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-private-rt-$((i+1))" --query 'RouteTables[0].RouteTableId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$PRIVATE_RT_ID" ] && [ "$PRIVATE_RT_ID" != "None" ]; then
              import_resource "module.vpc.aws_route_table.private[$i]" "$PRIVATE_RT_ID" "aws ec2 describe-route-tables --route-table-ids $PRIVATE_RT_ID --region ${{ env.AWS_REGION }}"
            fi
          done
          
          # Import Route Table Associations (public)
          for i in 0 1 2; do
            SUBNET_ID=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-public-subnet-$((i+1))" --query 'Subnets[0].SubnetId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_ID" ] && [ "$SUBNET_ID" != "None" ] && [ ! -z "$PUBLIC_RT_ID" ] && [ "$PUBLIC_RT_ID" != "None" ]; then
              ASSOC_ID=$(aws ec2 describe-route-tables --filters "Name=association.subnet-id,Values=$SUBNET_ID" --query 'RouteTables[0].Associations[0].RouteTableAssociationId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
              if [ ! -z "$ASSOC_ID" ] && [ "$ASSOC_ID" != "None" ]; then
                import_resource "module.vpc.aws_route_table_association.public[$i]" "$ASSOC_ID" "aws ec2 describe-route-tables --filters Name=association.route-table-association-id,Values=$ASSOC_ID --region ${{ env.AWS_REGION }}"
              fi
            fi
          done
          
          # Import Route Table Associations (private)
          for i in 0 1 2; do
            SUBNET_ID=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-private-subnet-$((i+1))" --query 'Subnets[0].SubnetId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
            if [ ! -z "$SUBNET_ID" ] && [ "$SUBNET_ID" != "None" ]; then
              ASSOC_ID=$(aws ec2 describe-route-tables --filters "Name=association.subnet-id,Values=$SUBNET_ID" --query 'RouteTables[0].Associations[0].RouteTableAssociationId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
              if [ ! -z "$ASSOC_ID" ] && [ "$ASSOC_ID" != "None" ]; then
                import_resource "module.vpc.aws_route_table_association.private[$i]" "$ASSOC_ID" "aws ec2 describe-route-tables --filters Name=association.route-table-association-id,Values=$ASSOC_ID --region ${{ env.AWS_REGION }}"
              fi
            fi
          done
        fi
        
        # ===== ECR RESOURCES =====
        echo "=== Importing ECR Resources ==="
        import_resource "aws_ecr_repository.ml_model" "ml-devops-dev-ml-model" "aws ecr describe-repositories --repository-names ml-devops-dev-ml-model --region ${{ env.AWS_REGION }}"
        
        # ===== ECS RESOURCES =====
        echo "=== Importing ECS Resources ==="
        import_resource "aws_ecs_cluster.main" "ml-devops-dev-cluster" "aws ecs describe-clusters --clusters ml-devops-dev-cluster --region ${{ env.AWS_REGION }}"
        import_resource "aws_ecs_task_definition.main" "ml-devops-dev-task" "aws ecs describe-task-definition --task-definition ml-devops-dev-task --region ${{ env.AWS_REGION }}"
        import_resource "aws_ecs_service.main" "ml-devops-dev-service" "aws ecs describe-services --cluster ml-devops-dev-cluster --services ml-devops-dev-service --region ${{ env.AWS_REGION }}"
        
        # ===== ALB RESOURCES =====
        echo "=== Importing ALB Resources ==="
        ALB_ARN=$(aws elbv2 describe-load-balancers --names ml-devops-dev-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        if [ ! -z "$ALB_ARN" ] && [ "$ALB_ARN" != "None" ]; then
          import_resource "aws_lb.main" "$ALB_ARN" "aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --region ${{ env.AWS_REGION }}"
        fi
        
        TG_ARN=$(aws elbv2 describe-target-groups --names ml-devops-dev-tg --query 'TargetGroups[0].TargetGroupArn' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
        if [ ! -z "$TG_ARN" ] && [ "$TG_ARN" != "None" ]; then
          import_resource "aws_lb_target_group.main" "$TG_ARN" "aws elbv2 describe-target-groups --target-group-arns $TG_ARN --region ${{ env.AWS_REGION }}"
        fi
        
        if [ ! -z "$ALB_ARN" ] && [ "$ALB_ARN" != "None" ]; then
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn "$ALB_ARN" --query 'Listeners[0].ListenerArn' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          if [ ! -z "$LISTENER_ARN" ] && [ "$LISTENER_ARN" != "None" ]; then
            import_resource "aws_lb_listener.main" "$LISTENER_ARN" "aws elbv2 describe-listeners --listener-arns $LISTENER_ARN --region ${{ env.AWS_REGION }}"
          fi
        fi
        
        # ===== SECURITY GROUP RESOURCES =====
        echo "=== Importing Security Group Resources ==="
        if [ ! -z "$VPC_ID" ] && [ "$VPC_ID" != "None" ]; then
          # ALB Security Group
          ALB_SG_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-alb-sg" --query 'SecurityGroups[0].GroupId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          if [ ! -z "$ALB_SG_ID" ] && [ "$ALB_SG_ID" != "None" ]; then
            import_resource "aws_security_group.alb" "$ALB_SG_ID" "aws ec2 describe-security-groups --group-ids $ALB_SG_ID --region ${{ env.AWS_REGION }}"
          fi
          
          # ECS Tasks Security Group
          ECS_SG_ID=$(aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Name,Values=ml-devops-dev-ecs-tasks-sg" --query 'SecurityGroups[0].GroupId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          if [ ! -z "$ECS_SG_ID" ] && [ "$ECS_SG_ID" != "None" ]; then
            import_resource "aws_security_group.ecs_tasks" "$ECS_SG_ID" "aws ec2 describe-security-groups --group-ids $ECS_SG_ID --region ${{ env.AWS_REGION }}"
          fi
        fi
        
        # ===== IAM RESOURCES =====
        echo "=== Importing IAM Resources ==="
        import_resource "aws_iam_role.ecs_execution_role" "ml-devops-dev-ecs-execution-role" "aws iam get-role --role-name ml-devops-dev-ecs-execution-role --region ${{ env.AWS_REGION }}"
        import_resource "aws_iam_role.ecs_task_role" "ml-devops-dev-ecs-task-role" "aws iam get-role --role-name ml-devops-dev-ecs-task-role --region ${{ env.AWS_REGION }}"
        
        # Import IAM Role Policies
        import_resource "aws_iam_role_policy.ecs_execution_role_policy" "ml-devops-dev-ecs-execution-role:ml-devops-dev-ecs-execution-policy" "aws iam get-role-policy --role-name ml-devops-dev-ecs-execution-role --policy-name ml-devops-dev-ecs-execution-policy --region ${{ env.AWS_REGION }}"
        import_resource "aws_iam_role_policy.ecs_task_role_policy" "ml-devops-dev-ecs-task-role:ml-devops-dev-ecs-task-policy" "aws iam get-role-policy --role-name ml-devops-dev-ecs-task-role --policy-name ml-devops-dev-ecs-task-policy --region ${{ env.AWS_REGION }}"
        
        # ===== AUTOSCALING RESOURCES =====
        echo "=== Importing Auto Scaling Resources ==="
        import_resource "aws_appautoscaling_target.ecs_target" "service/ml-devops-dev-cluster/ml-devops-dev-service" "aws application-autoscaling describe-scalable-targets --service-namespace ecs --resource-ids service/ml-devops-dev-cluster/ml-devops-dev-service --region ${{ env.AWS_REGION }}"
        import_resource "aws_appautoscaling_policy.ecs_policy_cpu" "ml-devops-dev-cpu-scaling" "aws application-autoscaling describe-scaling-policies --service-namespace ecs --policy-names ml-devops-dev-cpu-scaling --region ${{ env.AWS_REGION }}"
        import_resource "aws_appautoscaling_policy.ecs_policy_memory" "ml-devops-dev-memory-scaling" "aws application-autoscaling describe-scaling-policies --service-namespace ecs --policy-names ml-devops-dev-memory-scaling --region ${{ env.AWS_REGION }}"
        
        # ===== CLOUDWATCH RESOURCES =====
        echo "=== Importing CloudWatch Resources ==="
        import_resource "aws_cloudwatch_log_group.main" "/ecs/ml-devops-dev" "aws logs describe-log-groups --log-group-name-prefix /ecs/ml-devops-dev --region ${{ env.AWS_REGION }}"
        import_resource "aws_cloudwatch_dashboard.main" "ml-devops-dev-dashboard" "aws cloudwatch get-dashboard --dashboard-name ml-devops-dev-dashboard --region ${{ env.AWS_REGION }}"
        
        echo "=== Resource import process completed ==="
      working-directory: infrastructure

    - name: Terraform Plan
      run: terraform plan -out=tfplan
      working-directory: infrastructure

    - name: Terraform Apply
      run: terraform apply -auto-approve
      working-directory: infrastructure

  build-and-deploy:
    needs: [test, infrastructure]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Wait for ECR repository
      run: |
        echo "Waiting for ECR repository to be created..."
        for i in {1..30}; do
          if aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "ECR repository is ready!"
            break
          fi
          echo "Attempt $i: ECR repository not ready yet, waiting 10 seconds..."
          sleep 10
        done
        
        # Verify repository exists
        aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} --region ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        cd ml-model
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:latest .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
        echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

    - name: Wait for ECS resources
      run: |
        echo "Waiting for ECS cluster and service to be created..."
        for i in {1..30}; do
          if aws ecs describe-clusters --clusters ${{ env.ECS_CLUSTER }} --region ${{ env.AWS_REGION }} --query 'clusters[0].status' --output text | grep -q "ACTIVE"; then
            echo "ECS cluster is ready!"
            break
          fi
          echo "Attempt $i: ECS cluster not ready yet, waiting 10 seconds..."
          sleep 10
        done
        
        # Verify cluster exists and is active
        aws ecs describe-clusters --clusters ${{ env.ECS_CLUSTER }} --region ${{ env.AWS_REGION }}

    - name: Get ECS task definition details
      id: get-task-def
      run: |
        # Get the current task definition
        TASK_DEF_ARN=$(aws ecs describe-services --cluster ${{ env.ECS_CLUSTER }} --services ${{ env.ECS_SERVICE }} --query 'services[0].taskDefinition' --output text)
        echo "Current task definition: $TASK_DEF_ARN"
        
        # Get task definition details
        aws ecs describe-task-definition --task-definition $TASK_DEF_ARN --query 'taskDefinition' > task-definition.json
        echo "task-definition-arn=$TASK_DEF_ARN" >> $GITHUB_OUTPUT

    - name: Fill in the new image ID in the Amazon ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: ml-devops-dev-container
        image: ${{ steps.build-image.outputs.image }}

    - name: Deploy Amazon ECS task definition
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: ${{ env.ECS_SERVICE }}
        cluster: ${{ env.ECS_CLUSTER }}
        wait-for-service-stability: true

    - name: Run health check
      run: |
        echo "Waiting for service to be healthy..."
        sleep 60
        ALB_DNS=$(aws elbv2 describe-load-balancers --names ml-devops-dev-alb --query 'LoadBalancers[0].DNSName' --output text)
        echo "Testing health endpoint: http://$ALB_DNS/health"
        curl -f http://$ALB_DNS/health || exit 1
        echo "Health check passed!"

  security-scan:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

